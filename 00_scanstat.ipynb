{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scanstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import special\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scanstat\n",
    "\n",
    "> The functions that help detect clusters in point processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def correct_intervals(data):\n",
    "    '''\n",
    "    returns elements of all possible correct intervals, assumes `data` is sorted, small to large\n",
    "    '''\n",
    "    a = data\n",
    "    n = len(data)\n",
    "    a = list(range(0, n))\n",
    "    b = list(range(0, n))\n",
    "    c = []\n",
    "    d = []\n",
    "    for i in range(0, len(a)):\n",
    "        b.pop(0)\n",
    "        a.pop()\n",
    "        c.extend(a)\n",
    "        d.extend(b)\n",
    "    X_i = c\n",
    "    X_j = d\n",
    "    \n",
    "    return c, d\n",
    "\n",
    "\n",
    "def normalize(a):\n",
    "    '''\n",
    "    Normalize to [0, 1]\n",
    "    '''\n",
    "    a = sorted([float(ai) for ai in a])\n",
    "    normalized_a = []\n",
    "    y = min(a)\n",
    "    z = max(a)\n",
    "    normalized_a = [(ai - y) / (z - y) for ai in a] \n",
    "    \n",
    "    return normalized_a\n",
    "\n",
    "\n",
    "def ibf(x, a, b): \n",
    "    '''\n",
    "    Incomplete beta function, vectorized\n",
    "    '''\n",
    "    return beta.cdf(x = x, a = a,  b = b) * special.beta(a, b)\n",
    "\n",
    "\n",
    "def transform(cluster_location, data, verbose=False):\n",
    "    '''\n",
    "    Trainsform values around significant cluster\n",
    "    '''\n",
    "    i = cluster_location[0]\n",
    "    j = cluster_location[1]\n",
    "    n = len(data)\n",
    "    t = 1 - data[j] + data[i]\n",
    "    \n",
    "    new_data = []\n",
    "    \n",
    "    for k in range(n):\n",
    "        if ((0 <= k) and (k <= i)): \n",
    "            new_data.append(data[k] / t)\n",
    "        elif (((i + 1) <= k) and (k <= ((n - 1) - j + i))): \n",
    "            # n-1 important here because len(data) is greater than the numeral of the last element in data, i.e., if len(data) = 10, data[10] will fail\n",
    "            new_data.append((data[k + j - i] - data[j] + data[i]) / t)\n",
    "            \n",
    "        if verbose == True: \n",
    "            print (f'repositioning data: [ {k} : , {data[k]} ] \\n')\n",
    "            \n",
    "    return new_data\n",
    "\n",
    "\n",
    "def get_cluster(data, type=\"min\", stat_dist=False): # cluster detection\n",
    "    '''\n",
    "    Find initial cluster\n",
    "    '''\n",
    "    if len(data) < 3:\n",
    "        raise Exception('Need more than two data points')\n",
    "        \n",
    "    if stat_dist == True: \n",
    "        data = list(np.random.uniform(0, 1, len(data))) #\n",
    "        \n",
    "    data = list(set(data)) # remove duplicated values\n",
    "    n = len(data)\n",
    "    data = sorted(data)\n",
    "    data = normalize(data)\n",
    "\n",
    "    #get all correct intervals\n",
    "    i, j = correct_intervals(data)\n",
    "    \n",
    "    #compute the statistic\n",
    "    I_H_F = float(1) / ibf((np.array(data)[j] - np.array(data)[i]), np.array(j) - np.array(i), (n) + 1 - np.array(j) + np.array(i))\n",
    "    I_H_F = list(I_H_F)\n",
    "    I_H_F_max_loc = I_H_F.index(max(I_H_F))\n",
    "    I_H_F_min_loc = I_H_F.index(min(I_H_F))\n",
    "  \n",
    "    full_data_max = {\n",
    "        'X_i': [data[i[I_H_F_max_loc]]],\n",
    "        'X_j': [data[j[I_H_F_max_loc]]],\n",
    "        'i': [i[I_H_F_max_loc]],\n",
    "        'j': [j[I_H_F_max_loc]],\n",
    "        'I_H_F': [I_H_F[I_H_F_max_loc]]\n",
    "    }\n",
    "\n",
    "    full_data_min = {\n",
    "        'X_i': [data[i[I_H_F_min_loc]]],\n",
    "        'X_j': [data[j[I_H_F_min_loc]]],\n",
    "        'i': [i[I_H_F_min_loc]],\n",
    "        'j': [j[I_H_F_min_loc]],\n",
    "        'I_H_F': [I_H_F[I_H_F_min_loc]]\n",
    "    }\n",
    "  \n",
    "    if type == 'max': return full_data_max \n",
    "    if type == 'min': return full_data_min\n",
    "\n",
    "\n",
    "def get_ps(data, clust_table, permutations, type='max'):\n",
    "    '''\n",
    "    Compute p-value\n",
    "    '''\n",
    "    if len(data) < 3 : return clust_table\n",
    "    else:\n",
    "        L = []\n",
    "        for i in range(permutations):\n",
    "            table = get_cluster(data, stat_dist=True)\n",
    "            L.append(table['I_H_F'][-1])\n",
    "\n",
    "        L = sorted(L)\n",
    "        if type == 'max': \n",
    "            A_H_F_p = 1. - sum(1. * ((np.array(L) < clust_table[\"I_H_F\"][-1])) / len(L))\n",
    "        if type == 'min': \n",
    "            A_H_F_p = sum(1. * ((np.array(L) < clust_table[\"I_H_F\"][-1])) / len(L))\n",
    "\n",
    "        clust_table['ps'][-1] = A_H_F_p\n",
    "\n",
    "        return clust_table    \n",
    "\n",
    "def get_clusters(data, type='max', permutations=1000, p=0.05):\n",
    "    clust_table = get_cluster(data, type=type)\n",
    "    data = list(set(data))\n",
    "    data = sorted(data)\n",
    "    data = normalize(data)\n",
    "    clust_table['ps'] = [float(0.0)]\n",
    "    clust_table = get_ps(data, clust_table, permutations, type=type)\n",
    "    \n",
    "    while (clust_table['ps'][-1] < p):\n",
    "        i = clust_table['i'][-1]\n",
    "        j = clust_table['j'][-1]\n",
    "        \n",
    "        data = transform([i, j], data)\n",
    "        \n",
    "        new_clust_table = get_cluster(data)\n",
    "        new_clust_table['ps'] = [float(0.0)]\n",
    "        new_clust_table_with_ps = get_ps(data, new_clust_table, permutations, type=type)\n",
    "        \n",
    "        for ii in new_clust_table_with_ps.keys():\n",
    "            clust_table[ii].extend(new_clust_table_with_ps[ii])\n",
    "            \n",
    "    return pd.DataFrame(clust_table).pipe(lambda x: x[x.loc[:, 'ps'] <= p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis free scan statistic\n",
    "\n",
    "Python implementation of the hypothesis-free multiple scan statistic with variable window for detecting clusters in point processes (L. Cucala. A hypothesis-free multiple scan statistic with variable window. Biom. J., 50 (2008), pp. 299-310). The algorithm uses a Monte Carlo procedure to compute p-values.\n",
    "\n",
    "See the below example using data from Knox, G. (1959). Secular pattern of congenital oesophageal atresia. British Journal of Preventive Social Medecine 13, 222â€“226."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knox_1959 = [170, 316, 445, 468, 938, 1034, 1128, 1233, 1248, 1249,\n",
    "        1252, 1259, 1267, 1305, 1385, 1388, 1390, 1446, 1454,\n",
    "        1458, 1461, 1491, 1583, 1699, 1702, 1787, 1924, 1974,\n",
    "        2049, 2051, 2067, 2075, 2108, 2151, 2174, 2191]\n",
    "\n",
    "clusters = get_clusters(knox_1959)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_i</th>\n",
       "      <th>X_j</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>I_H_F</th>\n",
       "      <th>ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525977</td>\n",
       "      <td>0.653637</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>7.319199e+14</td>\n",
       "      <td>-6.661338e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X_i       X_j  i   j         I_H_F            ps\n",
       "0  0.525977  0.653637  7  21  7.319199e+14 -6.661338e-16"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233 1491\n"
     ]
    }
   ],
   "source": [
    "print(knox_1959[7], knox_1959[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
